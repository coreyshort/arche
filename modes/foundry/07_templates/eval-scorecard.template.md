# Eval Scorecard Template

Record results of running eval scenarios.

## Rubric reference
- Primary rubric: `09_learning/rubrics/[rubric-name].md`
- Secondary rubrics: [optional]

## Runs

| Date | Scenario | Artifact scored | Score summary | Pass/Fail | Notes | Links |
|------|----------|-----------------|---------------|----------|-------|-------|
| YYYY-MM-DD | SC-NNNN | [artifact name] | [score] | [Pass/Fail] | [notes] | [link] |
| YYYY-MM-DD | SC-NNNN | [artifact name] | [score] | [Pass/Fail] | [notes] | [link] |

## Analysis

### Overall trend
- [Are scores improving? Stable? Declining?]

### Most recent run
- Scenario: [Last scenario run]
- Date: [Date]
- Result: [Pass/Fail and key finding]

### Issues found
- [Any blocking issues discovered]

### Next actions
- [Recommended improvements or scenarios to run next]
